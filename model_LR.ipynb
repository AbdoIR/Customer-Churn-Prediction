{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f974f73f",
   "metadata": {},
   "source": [
    "<h1>logistic Regression</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7992c232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7932\n",
      "Logistic Regression F1-Score: 0.5557\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Load the split files\n",
    "train = pd.read_csv('train_data.csv')\n",
    "test = pd.read_csv('test_data.csv')\n",
    "\n",
    "X_train, y_train = train.drop('Churn', axis=1), train['Churn']\n",
    "X_test, y_test = test.drop('Churn', axis=1), test['Churn']\n",
    "\n",
    "# Model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_score(y_test, preds):.4f}\")\n",
    "print(f\"Logistic Regression F1-Score: {f1_score(y_test, preds):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8316d840",
   "metadata": {},
   "source": [
    "<h1>Random forest  </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ca6b252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7861\n",
      "Random Forest F1-Score: 0.5419\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "print(f\"Random Forest Accuracy: {accuracy_score(y_test, preds):.4f}\")\n",
    "print(f\"Random Forest F1-Score: {f1_score(y_test, preds):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eac9322",
   "metadata": {},
   "source": [
    "<h1> XGboost</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12d92484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- XGBoost Performance ---\n",
      "Accuracy: 0.7846\n",
      "F1-Score: 0.5615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aymen\\miniconda3\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [01:27:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier(\n",
    "    use_label_encoder=False, \n",
    "    eval_metric='logloss', \n",
    "    random_state=42,\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "print(\"--- XGBoost Performance ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, preds):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, preds):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcfec47",
   "metadata": {},
   "source": [
    "<h1> ANN  </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "479740d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ANN Performance ---\n",
      "Accuracy: 0.7790\n",
      "F1-Score: 0.5486\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "# a basic Neural Network\n",
    "# hidden_layer_sizes=(16, 8) means 2 hidden layers with 16 and 8 neurons in case one of you dumbfucks didn't understand\n",
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(16, 8), \n",
    "    max_iter=1000, \n",
    "    random_state=42,\n",
    "    activation='relu',\n",
    "    solver='adam'\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"--- ANN Performance ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, preds):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, preds):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0843d42b",
   "metadata": {},
   "source": [
    "<p>not even ann could save it god help us  \t(︶︹︶)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fac1709",
   "metadata": {},
   "source": [
    "<h1>And the winner is Logistic Regression ୧༼ಠ益ಠ╭∩╮༽ </h1>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
